{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Batch 5 - ANN with Momentum.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DhilipSanjay/ANN-with-Momentum/blob/main/ANN_with_Momentum.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-t98ZIU7CqQn"
      },
      "source": [
        "# ANN with Momentum\n",
        "\n",
        "## Problem Statement - Classify image as cat or not cat\n",
        "\n",
        "## Steps\n",
        "1. Fix all hyperparameters \n",
        "  - Learning rate\n",
        "  - Number of epochs\n",
        "  - Number of unit in each layer\n",
        "  - Momentum\n",
        "1. Initialize and assign random weights and biases\n",
        "1. For each training example:\n",
        "  1. Calculate the output of each unit and propogate through the layers (forward)\n",
        "  1. Calculate the errors (for output and hidden layers)\n",
        "  1. Find change in weight (loss)\n",
        "  1. Update Weights\n",
        "\n",
        "## Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFzm336SKY2Q"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import h5py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqtdn2zVKxSS"
      },
      "source": [
        "## Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIEjc3L8868Z"
      },
      "source": [
        "def load_dataset():\n",
        "  file = \"/content/test_catvnoncat.h5\"\n",
        "  if os.path.exists(file) == False:\n",
        "    !wget https://github.com/amanchadha/coursera-deep-learning-specialization/raw/master/C1%20-%20Neural%20Networks%20and%20Deep%20Learning/Week%202/Logistic%20Regression%20as%20a%20Neural%20Network/datasets/test_catvnoncat.h5\n",
        "    !wget https://github.com/amanchadha/coursera-deep-learning-specialization/raw/master/C1%20-%20Neural%20Networks%20and%20Deep%20Learning/Week%202/Logistic%20Regression%20as%20a%20Neural%20Network/datasets/train_catvnoncat.h5\n",
        "  train_dataset = h5py.File('./train_catvnoncat.h5', \"r\")\n",
        "  train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
        "  train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
        "\n",
        "  test_dataset = h5py.File('./test_catvnoncat.h5', \"r\")\n",
        "  test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
        "  test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
        "\n",
        "  classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
        "  \n",
        "  train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
        "  test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
        "  \n",
        "  return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 842
        },
        "id": "wddumfM-Cg-N",
        "outputId": "61501c0f-c4cd-4e70-8e0e-330f0622fde3"
      },
      "source": [
        "x_train, y_train,x_test, y_test, classes = load_dataset()\n",
        "\n",
        "plt.imshow(x_test[23])\n",
        "print(y_test[0,23])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-29 17:25:42--  https://github.com/amanchadha/coursera-deep-learning-specialization/raw/master/C1%20-%20Neural%20Networks%20and%20Deep%20Learning/Week%202/Logistic%20Regression%20as%20a%20Neural%20Network/datasets/test_catvnoncat.h5\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://media.githubusercontent.com/media/amanchadha/coursera-deep-learning-specialization/master/C1%20-%20Neural%20Networks%20and%20Deep%20Learning/Week%202/Logistic%20Regression%20as%20a%20Neural%20Network/datasets/test_catvnoncat.h5 [following]\n",
            "--2021-03-29 17:25:43--  https://media.githubusercontent.com/media/amanchadha/coursera-deep-learning-specialization/master/C1%20-%20Neural%20Networks%20and%20Deep%20Learning/Week%202/Logistic%20Regression%20as%20a%20Neural%20Network/datasets/test_catvnoncat.h5\n",
            "Resolving media.githubusercontent.com (media.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to media.githubusercontent.com (media.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 616958 (602K) [application/octet-stream]\n",
            "Saving to: ‘test_catvnoncat.h5’\n",
            "\n",
            "test_catvnoncat.h5  100%[===================>] 602.50K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2021-03-29 17:25:43 (20.3 MB/s) - ‘test_catvnoncat.h5’ saved [616958/616958]\n",
            "\n",
            "--2021-03-29 17:25:43--  https://github.com/amanchadha/coursera-deep-learning-specialization/raw/master/C1%20-%20Neural%20Networks%20and%20Deep%20Learning/Week%202/Logistic%20Regression%20as%20a%20Neural%20Network/datasets/train_catvnoncat.h5\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://media.githubusercontent.com/media/amanchadha/coursera-deep-learning-specialization/master/C1%20-%20Neural%20Networks%20and%20Deep%20Learning/Week%202/Logistic%20Regression%20as%20a%20Neural%20Network/datasets/train_catvnoncat.h5 [following]\n",
            "--2021-03-29 17:25:43--  https://media.githubusercontent.com/media/amanchadha/coursera-deep-learning-specialization/master/C1%20-%20Neural%20Networks%20and%20Deep%20Learning/Week%202/Logistic%20Regression%20as%20a%20Neural%20Network/datasets/train_catvnoncat.h5\n",
            "Resolving media.githubusercontent.com (media.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to media.githubusercontent.com (media.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2572022 (2.5M) [application/octet-stream]\n",
            "Saving to: ‘train_catvnoncat.h5’\n",
            "\n",
            "train_catvnoncat.h5 100%[===================>]   2.45M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2021-03-29 17:25:44 (30.5 MB/s) - ‘train_catvnoncat.h5’ saved [2572022/2572022]\n",
            "\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2da6xeV3nn/098iZ0LsWMnjh2bmGKHEEEu1YGCgqoUhirTqcoXhErLKDOKlC/MiGo6KjAjjdrRjARfSvkwQooGpvnAlEtbJhGq2oYUNBoxBMwkQK7kZic2dkwghpA4cXy85sN7Ob/9P2ctv/Y55z3H2c9fsrz3u/a79rPX2uu8//96nvWsKKUokUi8/nHeShuQSCSmgxzsiURPkIM9kegJcrAnEj1BDvZEoifIwZ5I9ASLGuwRcUtEPBYRT0TEJ5bKqEQisfSIs/WzR8QaST+W9H5JByV9T9KHSykPL515iURiqbB2Ed99p6QnSilPSVJEfEnSByRVB/vWrVvL7t27F3HLs8epU6fGxy+99NL4+OWXX+5ct379+vHxeed1ic/s7Oz4+OTJk+PjEydOdK5bu3auWXlfv/a1116byHb/g0w7eC9JWrNmzYLfa/1R53ckad26dQuW+XURMT5me7iNvPfx48er13kd/J73BcEyv47tc/755y94X6n7LBs3buyUXXTRRePjCy64oGrHasD+/fv1/PPPx0JlixnsV0p6FucHJf1G6wu7d+/Wvn37FnHLs8evfvWr8fF99903Pv7hD3/YuW7Xrl3jY74cUvePxM9+9rPx8TPPPNO5bvPmzePjV199tVN24MCB8fFzzz3XKfM/DLU6aAfvJUlveMMbxsetgcQyr+OKK64YH2/atGnBY6k7sJ5//vlO2Ysvvjg+fuWVV8bHDz/c/S04duxYtQ7auGHDhgXvK0kXXnjh+NgH6qWXXjo+fvOb3zw+/uUvf9m5jnVed911nbKbbrppfHzjjTdWv7caMDMzUy1bdksj4vaI2BcR+376058u9+0SiUQFi/llPyRpF853Dj/roJRyh6Q7JGlmZmZqgfhO0559do6EHD58eHzMXwWp+8volJOUn7+2pP6SdMkll4yPDx48WK3DfxX4C0ha6QyDdJr3krq0lZLBf9lZ9otf/KJTxrZziUKQ3jpoM21i+/q9+cx+b9ZBmSF1WQQZgNRlS0eOHBkfu6y5/PLLx8feL3xfrrnmmk6Zvz+rGYv5Zf+epL0R8aaIWC/p9yXdvTRmJRKJpcZZ/7KXUk5GxL+R9A+S1kj6QinloSWzLJFILCkWQ+NVSvk7SX+3RLYkEollxKIG+2oDdZjPtj766KPjY2pB11ycRHQtTg3POnx+gDrRZ9ipN92Nw1l2Xuez5XTZuevNbRnBtSyvc63M5+QMud+LcwzuwqSeZxu4+4595lqcZT7nQNB+7zO2FfvMr6NO97man/zkJ+PjJ598slP2tre9bcE6ViNWt3WJRGLJkIM9kegJXlc0nrTyiSeeqJaRSjrdJ71zqkd3EoNqnDqTftYCZaS2m6gWCed2ef2sk24uf04GGTl9Jh1l/V7Hz3/+86qNBOmz03gG6nhEYe177Eu31+n+li1bxseUbC5JWIfLGkoUuvmk9nOvNuQveyLRE+RgTyR6ghzsiURPcE5rdtdnLReJa7QRXIcyDHbr1q3VOnidh40yhNXrZ3jo0aNHO2XUg3TDebgs7+fuHtpM/c76vI6LL75YNbCNOU/hdrVW/rEO1+WXXXbZ+Njdd9TmtN/vxef0MvYT5wf8fajZK3XnLbwN+Dw+H7HakL/siURPkIM9kegJzmka/8ILL3TO77///vGxL6e96qqrxsekdh5Bx/XVTud4TveXr/OmK8sp+Pbt28fHTltJablCy9ez8zq60KRuVB7p7ZVXXtm5jtTU5QqlBt2Kvla85XZi5F3LFUl7fQUfJRDboLUSz9uU17aSbbRyBLAORmJK3VVwe/fuXfBeqwX5y55I9AQ52BOJnuCco/GtmdGnnnpqfOxUr7Zow6PHSMl9BpuUdufOndU6SBF9tpy03ukiF2CQnjvl5LP4vdk+lBqeNIL39vprM9NeB9vH6yAFZ1/4zD/llksSPx/B5QPPPZqRfc329UVInFX39Fi1yElJnTRrO3bsGB+3EnusFPKXPZHoCXKwJxI9QQ72RKInOOc0O10wTz/9dKeMSSW3bdvWKaP+a+Ujp171FU50ZdFN1NKr7jZr5Sdn2mPa6NqVOrflDqO9Ht3V0pTUvUzE2EoM4ZFxtcSXrqk5/0C3p1TPe+9uLc5b+FwNr6Vm97kDvgfeZ5zf8Pq5upJuueuvv75q40ohf9kTiZ4gB3si0ROcEzSe7iTm8KarTerSXUbMSV1qTbeLR1yRkjs9Z6QZaby7atxlR5DOuQuptrjGo/B47nXQLl7nkWukrb4ohPSfMsGpes3NJ3VlAyWV20Ga7UkpmHiC0sUXF9F+p+e19vZ7sa1aOfkotdyWhx6aS67s25x5lOJKIH/ZE4meIAd7ItET5GBPJHqCc0KzUys+/vjj42Mmq3C08oLz2DU77+X6j9qwtZKLWt/LeO5zArS5tWsp3Ve+ao828jq3g2HB3gask8eebINt4PMUdFdxjsRzsrMO18PU/XQBumZvJYRkO/o7QXC+x+cwGCLrrk5ey/kkT57SSpwxLZz2lz0ivhARRyPiQXx2aUTcExGPD//f3KojkUisPCah8X8p6Rb77BOS7i2l7JV07/A8kUisYpyWT5RS/ndE7LaPPyDp5uHxnZK+JenjS2hXB3RJMVe5R5ZxVZa7T3heo7pSlwb6qjRSQl7nLinSVnfxkMY6natt/+vXkfp6RFeLuhOkox4xNmn0G91V/py1vPce2cgEJE6zazn8+Q54HR4pWMsRV1tRJ81vNz63ywS+c3SXPvfcc53raDMlyTRxthN020opI4FyRNK21sWJRGLlsejZ+DL4s13NTxQRt0fEvojY56miEonE9HC204LPRcT2UsrhiNgu6WjtwlLKHZLukKSZmZlF75VDiuX0c8+ePQteJ9V3AXVq2kp7XIvA8gUcta2mpC599DLa3Fr4QQruz0XaTZrtEqGVyIFlfDan2XwWr5+z85yJ9n7hs3ikIOUEy5jHT+rKK38W0u7WdlWk4P6cbP9Wzj8+s3snDh48OD52L4/P8C8XzvaX/W5Jtw6Pb5V019KYk0gklguTuN7+StL/lfSWiDgYEbdJ+pSk90fE45L+2fA8kUisYkwyG//hStH7ltiWRCKxjDgnIui4col6yrUOtZtHajHKilrZtRXv5XUwgoxlHtFF3ez6j9rW66f+o6b0uQnOM7RWm1HPu9bk6jjX20wC0prDoKZ2Lc7c9pOuNnOwfxlF6HVQb7tmp5ur9lxuoz8Ln9P3KqCep6vWV0Kyn3wF3K5duxasb6mRsfGJRE+Qgz2R6AnOCRpPCkSa5hFupGJOt0jbWnnGSdXdNcY6KAt8IQmTLviWRqTkTsFZP6mq02eeex1ctNFySfG8VT8pvl9HF1Jr99SaDJO6FNzlBNuA9bWSaLhbizKB7euLevgeuGzie+DvBJ+b22Z5HQTdcJJ0xRVXjI9bi3UWi/xlTyR6ghzsiURPkIM9kegJzgnNTrcLNZO73qiT3B1GFxt1kWswYtJYftdn1HGeYKM2/yDNnz+o1U+b3U3Ee7fcSbTD70tXE7d6djcl5yq8Dj4b3Un+LNTfbiPt5zNzLkLqanFvU84DtOYO/H0hau+f1J1XYNv7vALDjn3VXstVu5TIX/ZEoifIwZ5I9ATnBI0nSAl9Sx0mDHC6SLpFuui0r5WQgbSerhungIwe8yg52u+uJlK4lnuNq8jcflJcHntb8bwV/Vbb8tjP6Xbye1NuuSuSbezuUtbPdvOto+nq9DJScNrRkgwt+DtB0EaPDKQdLdfhciJ/2ROJniAHeyLRE5xzNL6WElrqzng6NSKt5Gyzz+y26NaRI0fGxwcOHBgf+wytR9QRpIuky24XKa1TcCZkcPsZkUbK7GmaSTlbXgFGpHl7OK2v1VFbhCR16S5TMUvd52zl9WvJMrZdTcr5uS+SYR2tHWT57vh1k24v5TJkKZG/7IlET5CDPZHoCXKwJxI9wTmh2WtuEXevUeP5KqzalkaukajdPJEktRX1q2tv6jh3SbX0ZS3pYctN5NFYbAO6BN0OJm3kqiu/X2vFF/W8PwuTZbAvXOezL3wVI9u4NT/Q2k6JdbANvD1oYysy098r9nUrcSTnAdxVy1VwdCMu9TZR+cueSPQEOdgTiZ7gnKDxBCksEzVIXfrp7hm6oVr510gXXSawjHZ4VFhtyyGp65KqLXzx+kntvE6XGnT/kDrSbSh1n8XtqOV5962PaKPbwWspSdytRTcU7yt13VXM6eZ9y3u7K5L9S5u8bylDvA6n7gTbhwuFvN/Z3u6a5WKpq6++enzsiTgWi/xlTyR6ghzsiURPkIM9kegJzgnNTp1HfeYuDOon1110Y9BF0tLUvu0utRvv5TnZeS8PdaXedHcS793Ssnw2XxHH+QLqUg/RZDiul9W2W3a9TQ3smr0WHupu1FbCEWpWujdb/e56nn1Ne103X3XVVQve1+13l10Nra26PeyY7xXbY+qaPSJ2RcQ3I+LhiHgoIj42/PzSiLgnIh4f/r/5dHUlEomVwyQ0/qSkPy6lXCvpXZI+GhHXSvqEpHtLKXsl3Ts8TyQSqxST7PV2WNLh4fGLEfGIpCslfUDSzcPL7pT0LUkfXw4jSXsYMeZUrLWSi9FppJgendaipnSt0CbPzcbtfZz60i6PuOLz7Ny5c3zsNJ6UkM8ldSk463NZQ5rpefLYBtw+yek+5Yu772rRdd4ebDtfxchz1u/tVssD5+d8lqeffrpzHZ/Z66cs86g2tgnv5e1N+eI0nv3ENvVtohaLM5qgi4jdkm6UdJ+kbcM/BJJ0RNK2JbUskUgsKSYe7BFxkaS/kfRHpZTODEkZ/NlaMIA9Im6PiH0RsW/SbK2JRGLpMdFgj4h1Ggz0L5ZS/nb48XMRsX1Yvl3S0YW+W0q5o5QyU0qZ8QUjiURiejitZo+BKPm8pEdKKX+Oorsl3SrpU8P/71oWC9XVNHR9uMarudekroaku8pdJAzB9QSItZzs7o7hSjp3jVG/uv28lq4g1+Wcc2hlj6nttyZJO3bsqNZB3cg5kpab0lffsc9ark4+s7sieS371uvgvIs/C/uX7ciwVKmbTNRDi1l/a9Ub7XfNzjb1sGPWyWw9b3zjGzvX+ftyppjEz36TpH8p6UcR8cDws/+gwSD/SkTcJumApA8typJEIrGsmGQ2/v9Iqu0Q/76lNSeRSCwXzokIOtJkum7O1kVCOuQ0nhTOXXu1bZe8Dp57FFQroSWp+7Ztc84Np46sw91+bCva4TbSneeuPSanZH58p5+taEC2FZNz+ipD3tupL9uHfd1KsulRj6yj9e7QzeWJLylXPB88+6YlNVjm7xXbcf/+/ePjt7/97Z3rXM6dKTI2PpHoCXKwJxI9waqk8R7VxsQFpDJOkTn77JFapEqs79ChQ53rSOM9Yoz0lvdyKk3q6ws/SEEZ0SVJ11xzjRaCU/DWVkW0pZWIo5bMw+/HXVyd3rYi+Sg16NXwtiK8PQja77PSrTx2tWQhrYUqLhMojbyslm/e+4g2el/wPWPUptP9pPGJRGIi5GBPJHqCHOyJRE+wKjW7a5pWTm+C7g53a1F3UXs++eSTnesY6eRuFq5EoyvFo8eo+91dxZDhPXv2VO1nnZ5YkzZ64gzq0lbiy5YLkHqTEWKeX55t4O5BanNGDfq9fF6EoAZu3Ys2+lwNn4Ua2DU1E2L4nAC1ss8nUWOz7V3b89zfq9pecv4si0X+sicSPUEO9kSiJ1iVNN6jsUj9SOHcNVHL5SV16S5p8TPPPFO9l0d7cfEIFyk4raTrzSkhI+PclUL6T3rYWmTiNNjp4wguf3ju1Jp0lPTZ3VV0fTrlZP2kvq2trFyusE72p1Nwug49cpLnfM5W4hOvg8/tcqi2DbQnT+Gz+MIpunRZ32IXvjjylz2R6AlysCcSPUEO9kSiJ1iVmt01cC0hXyuZgus6aqGWa6wVikrQDeV20L1G/S515yNaLjVe53MYtNF1Hcuo3z15RctNSe1JG13Ltlx7nO9gmetVhtK29DzdVT7XwXmX1qo6JhU5k620CW+rlkuQ4LO4/ewbhvvmXm+JROKskIM9kegJVg2NJ41yikXXUytKiRTL6TmpEmmlu65I4VpuLR5zFZ3UTaDw7LPPdspI9bx+Uj1Sd6fIrShC0thJJYlHdNEutqlvu8S+8NVmzC1H+/1ebEeXKwSlnLtVKQVaUqOVhILP5nbUVvBJdbec9y1db77KkPXz3fH3yiXKmSJ/2ROJniAHeyLRE6waGk966xFjpEqkc77lUCtCimW1hQd+vmXLlqq9pFgHDx7slJESOq2kXHH7+Zy0sbV1k1NC0mc+s8/a8zlbcoh016lvK8Uyn83TaROkpt5WteQbTuN57jbyPaillfay1gIUX3jE+3H2vJWDzuUV25tbcf3oRz/qXMdEIt5WkyB/2ROJniAHeyLRE+RgTyR6glWj2alzfatkajJqQXev0WXn7jtqK7quXONR27aSC9Kl5kkUqcFcX7IOvzfP+ZzuCuJ1roepnakhWy4vt5GgvnQty3Of+6Ampn51e2mX69xaAke3l9/zMt6P8yCtXPz+nCxruUH5LB6F19pnoNaO7rbl/AOjASfFaX/ZI2JDRHw3In4QEQ9FxJ8NP39TRNwXEU9ExJcjoj4Lk0gkVhyT0PhXJb23lHK9pBsk3RIR75L0aUmfKaXskfSCpNuWz8xEIrFYTLLXW5E08jesG/4rkt4r6Q+Gn98p6U8lfW7SG7vbiQsunBaT9rTca14nUdsR1F0wpFFOlWrRdU77anRc6lJyf05STtJsr5/fc/vpimvRfdbpcohUuGUvqbVH9fF+3FrJ3U7MB+htRarNfm9tqeVRfuwn1u80uxV92YrarCXpaG0d5n3B+/Gdc/lGWv/Wt761UzZJootJ92dfM9zB9aikeyQ9KelYKWX0xhyUdGXt+4lEYuUx0WAvpcyWUm6QtFPSOyUtvHXJAoiI2yNiX0Ts4x7YiURiujgj11sp5Zikb0p6t6RNETHiwzslHap8545SykwpZYbrvBOJxHRxWs0eEZdJeq2UciwiNkp6vwaTc9+U9EFJX5J0q6S7zuTGngSA7jZP+MAQRepJ12fUTL5CiDqdes3DTVlHayUX3TjuKqTbz101rKPllmOdrtmpWV2z11bEuauJdXpfMPyXbd8K0fQ6aAfDjt0+PouHSVPf89jblH3R6vdWwg7W72W15BJexrZyVyTfVU8kUtuDzvfW+/a3v121Y/v27TodJvGzb5d0Z0Ss0YAJfKWU8vWIeFjSlyLiv0i6X9LnJ6grkUisECaZjf+hpBsX+PwpDfR7IpE4B7BiEXROK5kUwBft0wVBl4ZTQtI0d+PQNdHKFVbLUS91aTepmFNp0vFWAgl3/3iU2witrXtbdJG02N2ItL8V0dWKoOO9XZJQhrTyuteoutSlxZQ/7mbiudN4ltW2b/Z7t1ypniePbcc2cJrNd8llH9157FtvD44LXxE3yj3fet8yNj6R6AlysCcSPcGK0XinSqSqnueLZaRDTtlI452aEq1EApQMbiMjnVoRUaTIThdJfX1WlnSOs9RuYy1Xnd+P1N0jv1ppt3lvPltrIYy3ASn4oUNzXlmXXq32JgX3qDaCMsFn6km7WX+LxrtMYJ3uAeL3+D62dqdtyRDCpRHfaW4ZJc29S837VksSicTrCjnYE4meIAd7ItETrJhmd51C7eaRQ9QqdGm4G4Qr59ytVdsKya+jW8RdXtRrvHcrqaS772rbM0ldrcw6/TnpHnT7WQdXqbW2wfa5g9qWRv6c1IeuFXktXUatKDxP5kidXsv/LnW1cmubK84reL/wHfMybhfm9XO+gHX4vBPfHZ9Pqs3jtKIBfQ5j1D7pekskEjnYE4m+YMVovFNYUhSnnKTWpKncKkfq0ta9e/d2ykiPeC+PWiN18l1WucCFNM0pLOvw5yTc1UQKxud0yUNa7wkleE57Wy661g6stNHlBO3y+kmFea8f//jHneucFhM1d5u773idtxVpdiuPHSVEi+J7f7J+1uH90trOi+8gv+cSjefejqPFRi2Xc/6yJxI9QQ72RKInyMGeSPQEK6bZXSvfeOPcKlou0pe62nn//v3jY3fj7NmzZ3zs+7TVcqO7q4Ia1TUTy2pJC6SupvSwRoawuv3Um2wfnxOgpnStXNOGrYQJXgfbhDrd25B2uZ6vJV/069y9SdQSZrb2nHO3XG3vu0lXPvr9/H1hm9T26pO6feEJM/m+0LXs/c46vd2+8Y1vSJofzkvkL3si0RPkYE8keoIVo/FOUegq+8hHPtIpI83klrY7d+7sXHfVVVeNj51u0X1H2u0Zb0mVWvSWLhhPpMl8YJ7jjjS+Rc+Zh88p4aTuMKIV/eao0V2n8a2kETVXp1NkPktrS6aWi4402KUXXVl00bXu5e8O28pdarSrtXUY7+dtX8uv533Ld8JXGY7q8PYl8pc9kegJcrAnEj3BqtnFlfTlHe94R6eM9OirX/3q+NhnuknnfFaW563caS26SLpFOu5RS8wj5vW1ZtldNozgdK5mk9Sli630yKzT71uj1n4v1uHPQjrN9mht2eUUmXW2JIPnACS4iKU1a0+K31rY5PSc8pB97e3Bd9PLSMkZ9Vij6tL86M6RjUnjE4lEDvZEoi/IwZ5I9ASrRrMT7j667rrrxsfUl9ymSOrqHXet1KKxduzY0bmOesq1LMuo61oJDVp60vUr9SC3OXbNznkGXzlXWxHXinBznUe7eC/vF7aHz1uwvTm/0ZpLca3MfmJfuB217cG8jG3l9vJ7viqNfdharcn3wNub7eHuwVpue3+Ha9GA0lz7tLYtn/iXfbht8/0R8fXh+Zsi4r6IeCIivhwR609XRyKRWDmcCY3/mKRHcP5pSZ8ppeyR9IKk25bSsEQisbSYiMZHxE5J/0LSf5X072LA394r6Q+Gl9wp6U8lfW4ZbOxQoBtuuGF87HSOC/pbdIY01RcO0J03qVvLqV3LBdOiz6SZreQYtcQQUtct1dqtli4jp761xR1OTRk56BS8toWURxuy/prrUeq2gSe14DZXrd1ZW25Ennt7Uwr4+8Lnbi3WYXtQbrpdLdcvv+duytF70HLTTvrL/heS/kTSqKYtko6VUkZPcFDSlRPWlUgkVgCnHewR8buSjpZSvn82N4iI2yNiX0Ts8zj0RCIxPUzyy36TpN+LiP2SvqQBff+spE0RMeIwOyUdWujLpZQ7SikzpZQZp3CJRGJ6mGR/9k9K+qQkRcTNkv59KeUPI+Krkj6owR+AWyXdtYx2jsGF/9dee22nrLY6TqqvwvLtoan/3D3D802bNo2P3YVGPeUhva1tpXne0rLUf558kaC2dZ3LOj0sk0lAaIcn6WglxaSNvM63jqbG9FzrbEeGh7q7kc/imp3P1gofrtkk1VcSSt13qeUSba38q+2710o06n0xKlsKzb4QPq7BZN0TGmj4zy+irkQiscw4o6CaUsq3JH1rePyUpHcuvUmJRGI5sCoj6FqgW4T5uqTuarn777+/U/b000+Pj1vbBbW2biJdJC1z1xtdXl4/aVprKyTSfad9NdeYND+/2Qj+LDWKLHXz8bOtnO7z3i4TSNfp5vNnoR0uvdjenfp9hyOcu8uLffHK8Tl7W1s7u2xiWYvSM9KutbLN+4zS0e2qoZa/MLdsTiQSOdgTib7gnKPxhFMWzpB7AgzSu8cee2x83Mqr1qJirS2YSNU9UovXMqeY1M2HR7rrLks+p9fx6KOPLngvnwUnLW49J9uHdFPq0l2vgzPMPHaaTUrr0WnVRSzH67ugnjrV9XD8AhKCdH/DBV0vBim4yxXeu5VmmnZ4v/N73lbsp1qCFKnbHm7jSC7mLq6JRCIHeyLRF+RgTyR6gnNas7fgSSOo4Zlv/sEHH+xcR7eTRynV0EqE4GXUrx55R83OFU4PPPBA5zpq9t27d3fKrrjiigXrc71NHepzDnQlMkLPEz3STeTuO7o6qWvdNcg6PRqwFlE4L/HlSVxnkWtza7e67iqPXmRf+LwC9XFLz7fcd3yX/N6cJ2ol2PB7Ey037vg+p70ikUi8LpCDPZHoCV63NN7BSLZdu3aNj53u0y3HHWOlLrUm9WpF2jlFpqvM6Wht6ymn4My9R3ul7rNt27ZtfOwUmXTa3UmHDx8eH3Nxikd3sc6rr766U8b2oZvPFx613FqF+drPn5MWbsfLaOPz1liePNqE7/lCFZ67vCJ9drpMW9hn7tJtSYha/jun8SxzSj9q73S9JRKJHOyJRF+Qgz2R6Al6o9mJ1pbHTDbhZdTKdDW5BqPOfeaZZzpl1P2eeJCa7PLLLx8fu06kHT5fwDkBamW66/x7vjLPXWwjuB5kO7rrjZqS8yJX7uimKiyIYT3l22xjroIlru3pKvSyE68uvFXyayfryT5dD2/ZsqVaxhV9dNl5v/C6mt7277X2IawlVvG5iM59qiWJROJ1hRzsiURP0EsaT3rkriDSUc+GS5cU6bLTcZb5FlWk+J70gjST9N9pPLes8qQRtIVRW6SRUndFldN2lpFiOo0nlXR3lXDt7Cyi2MxtFufNPfMFZgcTT5AiO4WtbcvlZZMmJvFVaby3txXLKCF8iydSd+8z2lXbLtuvcztGNmfyikQikYM9kegLpkrjSyljauJRUDx3ulijJn4dZ8VbdIZwqkTq63SLOdIOHDgwPnYKy3OfBSeddmrNLZpol+c9Y0SdJzjgzDEX9Xh7kLa+8LNuhN7GC+coKCPtnJqSSjp9po2MIpy3LdcpJPo42pVNgWi4Vl4/0udWjjjS4NZurL4QprVtFOtp5ZmrbUPl967VJ3X7sOZBaT1//rInEj1BDvZEoifIwZ5I9ART1ewvvfSSvvOd70iarzW5Qst1Ea/lSqtW0gjXXdQyrW2TqWU9gq62dVMramP954oAAA5sSURBVKmlDV2/UudSv3siBNZJXS5124pReO5i5Eqxk6917Z/FczMxhLsiqRsvND2/edNcTn/27bykDpgXebXhamL/uS6tJbmQ6nM3Hp3GOQEv4/voWpnvY2srLr4jPl9VSxbi7wfbw/X8qI7WXNWk+7Pvl/SipFlJJ0spMxFxqaQvS9otab+kD5VSXqjVkUgkVhZnQuN/q5RyQyllZnj+CUn3llL2Srp3eJ5IJFYpFkPjPyDp5uHxnRrsAffx1heOHz+uhx9+WNJ8+kw3Dt1HUjcxAheqtCiLl9V20XQ3SCtBAKUBy7wORsk5bW1t70ObW7usks65O4zuPFJa3yrrGNI6vFzq0W+sw3Otv4bnfuHnXVLHHPAXQ1q4rGHZJmsb9tOkblXvi9q1TsfZxv4dygaXCURLHrLME6aw/tpuw1LXhVnbyXYpklcUSf8YEd+PiNuHn20rpYziR49I2rbwVxOJxGrApL/s7ymlHIqIyyXdExGPsrCUUiJiwT8pwz8Ot0vz9ypPJBLTw0S/7KWUQ8P/j0r6mgZbNT8XEdslafj/0cp37yilzJRSZpy+JBKJ6eG0v+wRcaGk80opLw6Pf1vSf5Z0t6RbJX1q+P9dp6trdnZ2HILqbgVqIbqMpK7OZTiruzqoB1270J0yb4VW5V6uu/jHiizFk0oyzNZzz1NjuwuptirLdT71pdfB8+N4zhOvdN1Jmy6d0/Br13br7+w9dqqhAWHXKb+uMv/gmprw56wlGTk123WJMrXFeY0w7NbquFaYKd9Nd8vRxlY4a80Or59t7/MbrNNDuUf1zwtHBiah8dskfW1o4FpJ/7OU8vcR8T1JX4mI2yQdkPShCepKJBIrhNMO9lLKU5KuX+Dzn0l633IYlUgklh5TjaCLiDHdaLm1mJxB6tIZ0kCnhKQwTstInUitnYKTpjklqrlFWq6gVsIHp3osY/u03JTuglm7Zs6ukyfgYjzZbatfIsnFRb4lE56H7eNtSmrakhNsA49KZBvP68+T7M85mzzij/WvXb+uWsZ+8nZrbdX9cmfVXtf+desXfie8fso3L6OsbLnvWts/jd5bb18iY+MTiZ4gB3si0RPkYE8keoKpa/aRTnWNR73Tyh5DHdPKGuI+fWpD6nK/F1eeeRm/13LjuBavoZWtp+XGYZnrS2rIEyfm7F3rNuF7nqnmoovn2q4VG0F96M8SCMd95cTcXITbO1txXUldt98sutp1eevdoe5fs7buVm3NP9Sdj/Xtlv1ZGD7smv3ULG2ce5bW/EaxstG1uddbIpHIwZ5I9AVTp/EjF5uvHuJqLd9KiPSZCRBbEUbz3CdwbzC3ukfT1ZJcSF3qVzuWurTSo/xIM93GWgSgX0dZ45SQbUBKOC+JJ2g2c7dL3TY5HzZdbC46Xuer+0jBuY3yrNlLaupReHS3rV0791yk5oPr5up3G+mm45ZPrYg57zPW4StAWvSf6Kzgc/vRv6Tns/b+naysAhx8b2BYut4SiUQO9kSiL5gqjT916tQ4gN+pOqmql9Vye7USVDjNIXWnZOBWTVKX7nIGVerO1LPMF7s0Z6lh86QeCafgpIRNGt9IlMHrSLO9jM/ibdrK23beOiRkwHP5desbO5/W9hKYtQi6iHpk2frz58o2bNxQva61tdIrL89JlNesL2pt/KK9O6WyHZYkzVZm0E+V7nWUXmts8dJFbxjIl9de6HpWiPxlTyR6ghzsiURPkIM9kegJpqrZT548Odbjvvh+79691e9x5dVll102Pm6tKHP9V0ua4DqUWtz1Zc3l5auRJs1B7i47gvX7c/J+Pp9BDdlamUeN6hGATMzBdvMVgq2tjDvX4t4XWkQe3Y2+9TVtPoF23Lixm2STrsPWPAjfD0/USXvnrTbbgD0IzE1ZWy23YUO3X1j/vDWSdL2hr9ec19XlTM55yaZLumVDl+OvXurOH3VsrZYkEonXFXKwJxI9wVRp/Pr167Vz505J8yN9SLeYd93LSJucPpN+OSUkPSedc9pH+uxSg/WTLjslpDSgu05yF0w9Dx/LWjnofJEM6yfNbiXicIpf2wLZo9NqufilLj2vLUKSJndTqhHx14pcY3/y3q1FJi0bvb1ZP6MD3b1GGz2KMFC2dt1cm/p239uQm3GzZWoe2d9yt+YveyLRE+RgTyR6ghzsiURPMFXNPjs7O3ZfeZhna4816lB+z11GtbzrXgfLXJ/RheRl1HXUqB5Wy+2RXQ9TR7vOpV21hI1SV9t7/bW5BG9v2uEuNdbB5BWu+1vzCr4icSHbpW4bt/YBILw9+CzzEmBwDmP93HWvvlrf2rmVz/+V43X7S2WLackSVLiuhsmtcOdfoZ/W2Ls/ujZXvSUSiRzsiURfMHUa7261EUjFtm7d2imjC4LUt5V33dFxfYBSuWRgHa0Itw61a1BTp1Wt+vk8pLAtqu6gtOEx29frcFpMOk07PEFFzUUndWUD5Ym3B+v3vmByDD7LyyY72G4tyUMbN5q7lH3mdvD8+EvdZCfrce8OpfdkIezDeas1sY0W3k1/rzo56CpSZtE0PiI2RcRfR8SjEfFIRLw7Ii6NiHsi4vHh/5tPX1MikVgpTErjPyvp70sp12iwFdQjkj4h6d5Syl5J9w7PE4nEKsUku7heIuk3Jf0rSSqlnJB0IiI+IOnm4WV3SvqWpI9PeuPW9kw+K8sZctIUj3Bj1NykC2FalNgXdzCC7PDhw+Njp1SklT7TXYuS8++xDVyu1BZ3SN3Z81ON2WGn9TU7+Gxex9nsjOsz7Ox3p8+1+n0mupVKms+yrkK53Y7WTqjnWwIM2hy/nHsfvT1aiTO4OKiV0472+7s56vfFRtC9SdJPJf2PiLg/Iv77cOvmbaWU0Rt/RIPdXhOJxCrFJIN9raRfl/S5UsqNkl6SUfYy+PO/YG6diLg9IvZFxL7WX/9EIrG8mGSwH5R0sJRy3/D8rzUY/M9FxHZJGv5/dKEvl1LuKKXMlFJmfMFIIpGYHibZn/1IRDwbEW8ppTymwZ7sDw//3SrpU8P/7zpdXadOnRq7b3xbIWqQSbf/dc1O15DraJZRr3kUHv8gucuLiSqplZ2x8NxtpEuqpcVbWwl5NBxRSxbpf2j9uQl+j/d2ncs6WisQqdP9vnwP3LVHlyujFOflqEdfux21PP3epsfRZ2HpJTZeMDd/4m3fyXuPBJGu7bkttr/7nJ9hG7v+Zh9eaqveRmWtrccm9bP/W0lfjEEaz6ck/WsNWMFXIuI2SQckfWjCuhKJxApgosFeSnlA0swCRe9bWnMSicRyYeoRdCM65hSFueXcfeLuqxE8Ao1Uz8tIj3jsCQL4PafgzGfPSEDPG0+K30rI4JST17KOlmvPXTCkhK1EGTxvudRaUYSk5E4f2We0w9ub3/OEIzXXobcb4fS8JkPmt8fcvU7Odqk636vW4qtLLpl7tnW20+zmzXMxZzt27OiUURrwvfJkIS03aGv31vF3TntFIpF4XSAHeyLRE+RgTyR6gqlqdqKVx9z1CDU8NV4r+YODeo2uINea1OnuZolKfu+WC62l8Xx1Xye3eCcHeT3E1N04RCuIie6rVugs790Kcfa2Yp53bnPsbjN+r7V9dmslIetoJZ/sJC2xJBTcNnnrli2dsmOYS/BQ7lqIs7spWebtXZtneQPyxHuZv/uj97YV6pu/7IlET5CDPZHoCWKSKfslu1nETzUIwNkq6fnTXL7cWA02SGmHI+3o4kztuKqUctlCBVMd7OObRuwrpSwUpNMrG9KOtGOadiSNTyR6ghzsiURPsFKD/Y4Vui+xGmyQ0g5H2tHFktmxIpo9kUhMH0njE4meYKqDPSJuiYjHIuKJiJhaNtqI+EJEHI2IB/HZ1FNhR8SuiPhmRDwcEQ9FxMdWwpaI2BAR342IHwzt+LPh52+KiPuG/fPlYf6CZUdErBnmN/z6StkREfsj4kcR8UBE7Bt+thLvyLKlbZ/aYI+INZL+m6R/LulaSR+OiGundPu/lHSLfbYSqbBPSvrjUsq1kt4l6aPDNpi2La9Kem8p5XpJN0i6JSLeJenTkj5TStkj6QVJty2zHSN8TIP05COslB2/VUq5Aa6ulXhHli9teyllKv8kvVvSP+D8k5I+OcX775b0IM4fk7R9eLxd0mPTsgU23CXp/Stpi6QLJP0/Sb+hQfDG2oX6axnvv3P4Ar9X0tc12OZwJezYL2mrfTbVfpF0iaSnNZxLW2o7pknjr5T0LM4PDj9bKaxoKuyI2C3pRkn3rYQtQ+r8gAaJQu+R9KSkY6WU0aqSafXPX0j6E0mj1S1bVsiOIukfI+L7EXH78LNp98uypm3PCTq1U2EvByLiIkl/I+mPSimd/Z6nZUspZbaUcoMGv6zvlHTNct/TERG/K+loKeX70773AnhPKeXXNZCZH42I32ThlPplUWnbT4dpDvZDknbhfOfws5XCRKmwlxoRsU6Dgf7FUsrfrqQtklRKOSbpmxrQ5U0RMVqTO43+uUnS70XEfklf0oDKf3YF7FAp5dDw/6OSvqbBH8Bp98ui0rafDtMc7N+TtHc407pe0u9LunuK93fcrUEKbGnCVNiLRQwWgH9e0iOllD9fKVsi4rKI2DQ83qjBvMEjGgz6D07LjlLKJ0spO0spuzV4H/6plPKH07YjIi6MiItHx5J+W9KDmnK/lFKOSHo2It4y/GiUtn1p7FjuiQ+baPgdST/WQB/+xyne968kHZb0mgZ/PW/TQBveK+lxSd+QdOkU7HiPBhTsh5IeGP77nWnbIuk6SfcP7XhQ0n8afv5rkr4r6QlJX5V0/hT76GZJX18JO4b3+8Hw30Ojd3OF3pEbJO0b9s3/krR5qezICLpEoifICbpEoifIwZ5I9AQ52BOJniAHeyLRE+RgTyR6ghzsiURPkIM9kegJcrAnEj3B/wdjxEaIFiH13QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntMORE8zK35h",
        "outputId": "51cc43ec-f5e4-448d-f46c-66c35ca4cb78"
      },
      "source": [
        "print(x_train.shape)\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], -1, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], -1, 1)\n",
        "\n",
        "x_train = x_train/255\n",
        "x_test = x_test/255\n",
        "\n",
        "print(\"Training data x-values:\", x_train.shape)\n",
        "print(\"Training data y-values:\", y_train.shape)\n",
        "print(\"Testing data x-values:\", x_test.shape)\n",
        "print(\"Testing data y-values:\",y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(209, 64, 64, 3)\n",
            "Training data x-values: (209, 12288, 1)\n",
            "Training data y-values: (1, 209)\n",
            "Testing data x-values: (50, 12288, 1)\n",
            "Testing data y-values: (1, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kROSrwWHDtXL"
      },
      "source": [
        "## Implementation\n",
        "\n",
        "## Initialize the Weights and Biases for the layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdBdITNVJcAS"
      },
      "source": [
        "def initialize_layers(layers):\n",
        "\n",
        "  np.random.seed(0)\n",
        "  # Store the weights and biases in dictionary\n",
        "  WB = {}\n",
        "  \n",
        "  for l in range(1, len(layers)):\n",
        "    # Weight dim = [current layer dim, prev layer dim]\n",
        "    WB[\"W\" + str(l)] =  np.random.randn(layers[l], layers[l-1]) * 0.01 #np.full((layers[l], layers[l-1]), 0.1)\n",
        "    print(\"W\"+str(l) , WB[\"W\" + str(l)].shape)\n",
        "\n",
        "    # Weight gradients initialized to zero (for backprop)\n",
        "    WB[\"dW\" + str(l)] =  np.zeros((layers[l], layers[l-1]))\n",
        "    print(\"dW\"+str(l) , WB[\"dW\" + str(l)].shape)\n",
        "\n",
        "    # Bias dim = [current layer dim]\n",
        "    WB[\"b\" + str(l)] = np.ones((layers[l], 1)) *0.01 #np.full(layers[l], 0.1)\n",
        "    print(\"b\"+str(l) , WB[\"b\" + str(l)].shape)\n",
        "\n",
        "    WB[\"db\" + str(l)] = np.zeros((layers[l], 1))\n",
        "    print(\"db\"+str(l) , WB[\"db\" + str(l)].shape)\n",
        "\n",
        "  return WB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyFxUbH2A6hr"
      },
      "source": [
        "## Activation Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wx_u7YlnA9xy"
      },
      "source": [
        "def sigmoid(net):\n",
        "  '''\n",
        "  Calculate sigmoid activation value\n",
        "  '''\n",
        "  return 1/(1+np.exp(-net))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frMl-iocAE_w"
      },
      "source": [
        "## Forward Propagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TaKQgEWAN7M"
      },
      "source": [
        "def linear_activation_forward(X, W, b):\n",
        "  '''\n",
        "  Calculate net value\n",
        "  Calculate the sigmoid activation value for net\n",
        "  \n",
        "  History - Stores the inputs, Weights and biases\n",
        "  '''\n",
        "  net = np.dot(W, X) + b\n",
        "  output = sigmoid(net)\n",
        "  history = (X, W, b)\n",
        "  \n",
        "  return output, history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiytvMEVFrAM"
      },
      "source": [
        "def model_linear_activation_forward(WB, X, layers):\n",
        "  '''\n",
        "  For an training example\n",
        "    store the history\n",
        "    Calculate it's output\n",
        "  '''\n",
        "  output = X\n",
        "  length = len(layers)\n",
        "  \n",
        "  for l in range(1, length):\n",
        "    output_prev = output\n",
        "    W = WB[\"W\" + str(l)]\n",
        "    b = WB[\"b\" + str(l)]\n",
        "    WB[\"X\" + str(l)] = output_prev\n",
        "    output, history = linear_activation_forward(output_prev, W, b)\n",
        "    \n",
        "  return output, WB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZWzxqDuLCaj"
      },
      "source": [
        "## Backward propagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-n8SU4dLIjr"
      },
      "source": [
        "def error_output_unit(T, O):\n",
        "  '''\n",
        "  T - Target Values\n",
        "  O - Output Values\n",
        "  '''\n",
        "  E = O * (1 - O) * (T - O)\n",
        "\n",
        "  return E"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GK9ssG5YUPqS"
      },
      "source": [
        "def error_hidden_unit(W, E, O):\n",
        "  '''\n",
        "  W - weight to the next layer\n",
        "  E - Error calculated for the next layer\n",
        "  O - Output of the current layer\n",
        "  '''\n",
        "  W = W.T\n",
        "  S = np.sum(np.dot(W, E))\n",
        "  E = O * (1 - O) * S\n",
        "  \n",
        "  return E"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8fTZEo0XqgB"
      },
      "source": [
        "def weight_update(W, b, E, X, LR, alpha, prevDW, prevDb):\n",
        "  '''\n",
        "  W - original weights\n",
        "  b - biases\n",
        "  E - Error values\n",
        "  X - Input values\n",
        "  LR - Learning Rate\n",
        "\n",
        "  dW - weight updates\n",
        "  db - bias updates\n",
        "\n",
        "  AW - altered weights\n",
        "  Ab - altered biases\n",
        "\n",
        "  alpha - momentum (if 0 -> no momentum)\n",
        "  prevDW - dW of previous iteration\n",
        "  prevDb - db of previous iteration\n",
        "  '''\n",
        "  dW = LR * np.dot(E, X.T)\n",
        "  db = LR * E * 1\n",
        "  # print(\"dW \", dW.shape)\n",
        "  AW = W  + dW + (alpha * prevDW)\n",
        "  Ab = b + db + (alpha * prevDb)\n",
        "  # print(\"AW \", AW.shape)\n",
        "\n",
        "  return AW, dW, Ab, db"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JT0lXaxvkHoa"
      },
      "source": [
        "def back_prop_output_unit(T, O, W, b, X, LR, alpha, prevDW, prevDb):\n",
        "  E = error_output_unit(T, O)\n",
        "  AW, dW, Ab, db = weight_update(W, b, E, X, LR, alpha, prevDW, prevDb)\n",
        "\n",
        "  return E, AW, dW, Ab, db\n",
        "\n",
        "def back_prop_hidden_unit(Wnext, Enext, O, W, b, X, LR, alpha, prevDW, prevDb):\n",
        "  E = error_hidden_unit(Wnext, Enext, O)\n",
        "  AW, dW, Ab, db = weight_update(W, b, E, X, LR, alpha, prevDW, prevDb)\n",
        "\n",
        "  return E, AW, dW, Ab, db"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZrrIm0hWjpj"
      },
      "source": [
        "def model_back_prop(WB, O, T, LR, layers, alpha):\n",
        "\n",
        "  length = len(layers) - 1\n",
        "  W = WB[\"W\" + str(length)] \n",
        "  X = WB[\"X\" + str(length)] \n",
        "  b = WB[\"b\" + str(length)]\n",
        "  prevDW = WB[\"dW\" + str(length)] \n",
        "  prevDb = WB[\"db\" + str(length)]\n",
        "  # temp = np.zeros((layers[-1], 1))\n",
        "  # temp[T] = 1\n",
        "  # T = temp\n",
        "\n",
        "  E, W, dW, b, db = back_prop_output_unit(T, O, W, b, X, LR, alpha, prevDW, prevDb)\n",
        "\n",
        "  # Update dW, db Error (for Adding momentum)\n",
        "  WB[\"dW\" + str(length)] = dW\n",
        "  WB[\"E\" + str(length)] = E\n",
        "  WB[\"db\" + str(length)] = db\n",
        "\n",
        "  # Update the weights, biases (for Adding momentum)\n",
        "  WB[\"W\" + str(length)] = W\n",
        "  WB[\"b\" + str(length)] = b\n",
        "  \n",
        "  for l in range(length-1, 0, -1):\n",
        "    # Next layers's weight and error (previously calculated)\n",
        "    Wnext = W\n",
        "    Enext = E\n",
        "\n",
        "    # Current layer's output (i.e) next layers input\n",
        "    O = X \n",
        "\n",
        "    # Current layer's weights and biases\n",
        "    W = WB[\"W\" + str(l)] \n",
        "    b = WB[\"b\" + str(l)]\n",
        "\n",
        "    # Input to current layer\n",
        "    X = WB[\"X\" + str(l)] \n",
        "    prevDW = WB[\"dW\" + str(l)] \n",
        "    prevDb = WB[\"db\" + str(l)]\n",
        "    \n",
        "    # Update weights\n",
        "    E, W, dW, Ab, db = back_prop_hidden_unit(Wnext, Enext, O, W, b, X, LR, alpha, prevDW, prevDb)\n",
        "    \n",
        "    # Update dW, db Error (for Adding momentum)\n",
        "    WB[\"dW\" + str(l)] = dW\n",
        "    WB[\"E\" + str(l)] = E\n",
        "    WB[\"db\" + str(l)] = db\n",
        "\n",
        "    # Update the weights, biases (for Adding momentum)\n",
        "    WB[\"W\" + str(l)] = W\n",
        "    WB[\"b\" + str(l)] = b\n",
        "  return WB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUlGjybZ6AZ1"
      },
      "source": [
        "# Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEY0v3Z55_6I"
      },
      "source": [
        "def train_model(WB, x_train, y_train, num_epochs, LR, layers, alpha):\n",
        "  total_ex = len(x_train)\n",
        "\n",
        "  # Run the model for the given number of epochs\n",
        "  for e in range(num_epochs):\n",
        "    print(\"Epoch \", e+1)\n",
        "    error = 0\n",
        "    accuracy = 0\n",
        "    for i in range(total_ex):\n",
        "      # Forward Propagation\n",
        "      output, WB = model_linear_activation_forward(WB, x_train[i], layers)\n",
        "      # Backward Propagation\n",
        "      WB = model_back_prop(WB, output, y_train[0, i], LR, layers, alpha)\n",
        "      # Accuracy and Erro\n",
        "      error += (y_train[0, i] - output) ** 2\n",
        "      if (output >= 0.5 and y_train[0, i] == 1) or (output < 0.5 and y_train[0, i] == 0):\n",
        "        accuracy += 1\n",
        "\n",
        "    # Calculate the final accuracy and error\n",
        "    final_error = np.squeeze(error)/total_ex\n",
        "    final_accuracy = accuracy/total_ex\n",
        "    print(\"Error: \", final_error, \"\\tAccuracy: \", final_accuracy)\n",
        "    \n",
        "    # To avoid overfitting\n",
        "    if final_accuracy >= 0.99:\n",
        "      print(\"99% Accuracy reached. Stopping the training\")\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bq3_LDBVDwIn"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQGCwM51G7-1"
      },
      "source": [
        "def model_predict(WB, X, layers):\n",
        "  output = X\n",
        "  \n",
        "  for l in range(1, len(layers)):\n",
        "    output_prev = output\n",
        "    W = WB[\"W\" + str(l)]\n",
        "    b = WB[\"b\" + str(l)]\n",
        "    output, history = linear_activation_forward(output_prev, W, b)\n",
        "\n",
        "  return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6xzolnT6qzL"
      },
      "source": [
        "def test_model(WB, x_test, y_test, layers):\n",
        "  total_ex = len(x_test)\n",
        "  error = 0\n",
        "  accuracy = 0\n",
        "  # Predict for all the test examples\n",
        "  for i in range(total_ex):\n",
        "    output = model_predict(WB, x_test[i], layers)\n",
        "    print(\"Predicted Output: \", np.squeeze(output),  \"\\tTest Output: \", y_test[0, i])\n",
        "\n",
        "    # Calculate the error and accuracy\n",
        "    error += (y_test[0, i] - output) ** 2\n",
        "    if (output >= 0.5 and y_test[0, i] == 1) or (output < 0.5 and y_test[0, i] == 0):\n",
        "      accuracy += 1\n",
        "\n",
        "  # Calculate the final accuracy and error\n",
        "  final_error = np.squeeze(error)/total_ex\n",
        "  final_accuracy = accuracy/total_ex\n",
        "  print(\"Error: \", final_error, \"\\tAccuracy: \", final_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVASVhHQMAwn"
      },
      "source": [
        "## ANN Without Momentum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHV-XOwA7TvG"
      },
      "source": [
        "input_layer = x_train.shape[1]\n",
        "hidden_1 = 16\n",
        "output_layer = 1 \n",
        "layers = [input_layer, hidden_1, output_layer]\n",
        "WB = initialize_layers(layers)\n",
        "\n",
        "num_epochs = 1000\n",
        "LR = 0.005\n",
        "alpha = 0\n",
        "train_model(WB, x_train, y_train, num_epochs, LR, layers, alpha)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmoxWMZdDUOq",
        "outputId": "f610ec88-1fe0-4472-ab0a-1a22cac42b45"
      },
      "source": [
        "# Without momentum test accuracy\n",
        "test_model(WB, x_test, y_test, layers)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted Output:  0.884018606053419 \tTest Output:  1\n",
            "Predicted Output:  0.8801337093945197 \tTest Output:  1\n",
            "Predicted Output:  0.885957128233154 \tTest Output:  1\n",
            "Predicted Output:  0.8763607305092223 \tTest Output:  1\n",
            "Predicted Output:  0.8577568765633424 \tTest Output:  1\n",
            "Predicted Output:  0.5926362158765595 \tTest Output:  0\n",
            "Predicted Output:  0.09486923341259497 \tTest Output:  1\n",
            "Predicted Output:  0.8834401260861943 \tTest Output:  1\n",
            "Predicted Output:  0.882482851720598 \tTest Output:  1\n",
            "Predicted Output:  0.8404548679885894 \tTest Output:  1\n",
            "Predicted Output:  0.4804485468995511 \tTest Output:  1\n",
            "Predicted Output:  0.8333873685054028 \tTest Output:  1\n",
            "Predicted Output:  0.825442147927578 \tTest Output:  1\n",
            "Predicted Output:  0.8857333926454172 \tTest Output:  0\n",
            "Predicted Output:  0.01276133521973673 \tTest Output:  0\n",
            "Predicted Output:  0.8588312604619821 \tTest Output:  1\n",
            "Predicted Output:  0.016115291607261863 \tTest Output:  0\n",
            "Predicted Output:  0.872504329988477 \tTest Output:  1\n",
            "Predicted Output:  0.4443716943319001 \tTest Output:  1\n",
            "Predicted Output:  0.07313956531575537 \tTest Output:  1\n",
            "Predicted Output:  0.8857452105371361 \tTest Output:  1\n",
            "Predicted Output:  0.01602671663865173 \tTest Output:  0\n",
            "Predicted Output:  0.00973444386601843 \tTest Output:  0\n",
            "Predicted Output:  0.8835238467087031 \tTest Output:  1\n",
            "Predicted Output:  0.4806106779158971 \tTest Output:  1\n",
            "Predicted Output:  0.798606398184233 \tTest Output:  1\n",
            "Predicted Output:  0.7163668171700764 \tTest Output:  1\n",
            "Predicted Output:  0.004210254555770092 \tTest Output:  0\n",
            "Predicted Output:  0.009886953049345566 \tTest Output:  1\n",
            "Predicted Output:  0.8828363451660264 \tTest Output:  0\n",
            "Predicted Output:  0.09071976485778373 \tTest Output:  1\n",
            "Predicted Output:  0.8781296560836954 \tTest Output:  1\n",
            "Predicted Output:  0.8662571296908406 \tTest Output:  1\n",
            "Predicted Output:  0.7694046910536589 \tTest Output:  1\n",
            "Predicted Output:  0.63252181939115 \tTest Output:  0\n",
            "Predicted Output:  0.20083855533994124 \tTest Output:  0\n",
            "Predicted Output:  0.10728207556208087 \tTest Output:  0\n",
            "Predicted Output:  0.8761951740368479 \tTest Output:  1\n",
            "Predicted Output:  0.5103572632416372 \tTest Output:  0\n",
            "Predicted Output:  0.03563294678451952 \tTest Output:  0\n",
            "Predicted Output:  0.8200371261136876 \tTest Output:  1\n",
            "Predicted Output:  0.48685541440421565 \tTest Output:  1\n",
            "Predicted Output:  0.8587490109065675 \tTest Output:  1\n",
            "Predicted Output:  0.007713494344466219 \tTest Output:  0\n",
            "Predicted Output:  0.88248213873562 \tTest Output:  0\n",
            "Predicted Output:  0.7138908984186704 \tTest Output:  0\n",
            "Predicted Output:  0.6389797090628991 \tTest Output:  1\n",
            "Predicted Output:  0.8870998637325662 \tTest Output:  1\n",
            "Predicted Output:  0.7443221816160247 \tTest Output:  1\n",
            "Predicted Output:  0.18467791072710787 \tTest Output:  0\n",
            "Error:  0.18565268315903358 \tAccuracy:  0.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1-BjXlQMJlp"
      },
      "source": [
        "## ANN With Momentum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wi8DU3z8MHgx",
        "outputId": "fbf122e1-4150-422b-c008-6562a999936d"
      },
      "source": [
        "input_layer = x_train.shape[1]\n",
        "hidden_1 = 16\n",
        "output_layer = 1 \n",
        "layers = [input_layer, hidden_1, output_layer]\n",
        "WB = initialize_layers(layers)\n",
        "\n",
        "num_epochs = 1000\n",
        "LR = 0.005\n",
        "alpha = 0.1\n",
        "train_model(WB, x_train, y_train, num_epochs, LR, layers, alpha)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W1 (16, 12288)\n",
            "dW1 (16, 12288)\n",
            "b1 (16, 1)\n",
            "db1 (16, 1)\n",
            "W2 (1, 16)\n",
            "dW2 (1, 16)\n",
            "b2 (1, 1)\n",
            "db2 (1, 1)\n",
            "Epoch  1\n",
            "Error:  0.24450183805787812 \tAccuracy:  0.5980861244019139\n",
            "Epoch  2\n",
            "Error:  0.2311361608177761 \tAccuracy:  0.6555023923444976\n",
            "Epoch  3\n",
            "Error:  0.227628882598047 \tAccuracy:  0.6555023923444976\n",
            "Epoch  4\n",
            "Error:  0.22695872529232824 \tAccuracy:  0.6555023923444976\n",
            "Epoch  5\n",
            "Error:  0.22668482471442528 \tAccuracy:  0.6555023923444976\n",
            "Epoch  6\n",
            "Error:  0.2263666548624873 \tAccuracy:  0.6555023923444976\n",
            "Epoch  7\n",
            "Error:  0.22568919568678444 \tAccuracy:  0.6555023923444976\n",
            "Epoch  8\n",
            "Error:  0.22428481192422614 \tAccuracy:  0.6555023923444976\n",
            "Epoch  9\n",
            "Error:  0.22240345929627142 \tAccuracy:  0.6555023923444976\n",
            "Epoch  10\n",
            "Error:  0.22019112495443416 \tAccuracy:  0.6555023923444976\n",
            "Epoch  11\n",
            "Error:  0.21773919901956923 \tAccuracy:  0.6555023923444976\n",
            "Epoch  12\n",
            "Error:  0.21511327062617558 \tAccuracy:  0.6555023923444976\n",
            "Epoch  13\n",
            "Error:  0.21242100045190349 \tAccuracy:  0.6555023923444976\n",
            "Epoch  14\n",
            "Error:  0.20949128130283973 \tAccuracy:  0.6555023923444976\n",
            "Epoch  15\n",
            "Error:  0.206483690520833 \tAccuracy:  0.6555023923444976\n",
            "Epoch  16\n",
            "Error:  0.20345962668250964 \tAccuracy:  0.6555023923444976\n",
            "Epoch  17\n",
            "Error:  0.20041510225181783 \tAccuracy:  0.6555023923444976\n",
            "Epoch  18\n",
            "Error:  0.19733601923939248 \tAccuracy:  0.6555023923444976\n",
            "Epoch  19\n",
            "Error:  0.19423981762378434 \tAccuracy:  0.6555023923444976\n",
            "Epoch  20\n",
            "Error:  0.19117737263125123 \tAccuracy:  0.6555023923444976\n",
            "Epoch  21\n",
            "Error:  0.18815720927661347 \tAccuracy:  0.6555023923444976\n",
            "Epoch  22\n",
            "Error:  0.18517294921236485 \tAccuracy:  0.6555023923444976\n",
            "Epoch  23\n",
            "Error:  0.18220699514202093 \tAccuracy:  0.6555023923444976\n",
            "Epoch  24\n",
            "Error:  0.17923354866498561 \tAccuracy:  0.6555023923444976\n",
            "Epoch  25\n",
            "Error:  0.1762221076910272 \tAccuracy:  0.6602870813397129\n",
            "Epoch  26\n",
            "Error:  0.1731592688747462 \tAccuracy:  0.6698564593301436\n",
            "Epoch  27\n",
            "Error:  0.17000123972875458 \tAccuracy:  0.6650717703349283\n",
            "Epoch  28\n",
            "Error:  0.16679200193175997 \tAccuracy:  0.6889952153110048\n",
            "Epoch  29\n",
            "Error:  0.1636308953374776 \tAccuracy:  0.6985645933014354\n",
            "Epoch  30\n",
            "Error:  0.16055233401093788 \tAccuracy:  0.7081339712918661\n",
            "Epoch  31\n",
            "Error:  0.15756537958302308 \tAccuracy:  0.7177033492822966\n",
            "Epoch  32\n",
            "Error:  0.15466662657309102 \tAccuracy:  0.722488038277512\n",
            "Epoch  33\n",
            "Error:  0.15185015020058892 \tAccuracy:  0.7320574162679426\n",
            "Epoch  34\n",
            "Error:  0.14911081177789273 \tAccuracy:  0.7416267942583732\n",
            "Epoch  35\n",
            "Error:  0.1464456457088077 \tAccuracy:  0.7559808612440191\n",
            "Epoch  36\n",
            "Error:  0.14385421092252967 \tAccuracy:  0.7799043062200957\n",
            "Epoch  37\n",
            "Error:  0.14133783986521606 \tAccuracy:  0.8038277511961722\n",
            "Epoch  38\n",
            "Error:  0.13889865674824028 \tAccuracy:  0.8038277511961722\n",
            "Epoch  39\n",
            "Error:  0.136538646734531 \tAccuracy:  0.8181818181818182\n",
            "Epoch  40\n",
            "Error:  0.13425892326768288 \tAccuracy:  0.8181818181818182\n",
            "Epoch  41\n",
            "Error:  0.1320593255909721 \tAccuracy:  0.8421052631578947\n",
            "Epoch  42\n",
            "Error:  0.129938304120108 \tAccuracy:  0.8516746411483254\n",
            "Epoch  43\n",
            "Error:  0.12789298476697628 \tAccuracy:  0.8516746411483254\n",
            "Epoch  44\n",
            "Error:  0.12591949229432936 \tAccuracy:  0.8564593301435407\n",
            "Epoch  45\n",
            "Error:  0.12401394788889837 \tAccuracy:  0.8660287081339713\n",
            "Epoch  46\n",
            "Error:  0.12217396424795071 \tAccuracy:  0.8755980861244019\n",
            "Epoch  47\n",
            "Error:  0.12039798038799254 \tAccuracy:  0.8899521531100478\n",
            "Epoch  48\n",
            "Error:  0.11868171024278498 \tAccuracy:  0.8947368421052632\n",
            "Epoch  49\n",
            "Error:  0.1170171938638887 \tAccuracy:  0.8899521531100478\n",
            "Epoch  50\n",
            "Error:  0.11539762362956724 \tAccuracy:  0.8995215311004785\n",
            "Epoch  51\n",
            "Error:  0.11382077587568978 \tAccuracy:  0.9043062200956937\n",
            "Epoch  52\n",
            "Error:  0.11227886943872623 \tAccuracy:  0.8995215311004785\n",
            "Epoch  53\n",
            "Error:  0.11075607812100974 \tAccuracy:  0.9043062200956937\n",
            "Epoch  54\n",
            "Error:  0.10924782003672505 \tAccuracy:  0.9090909090909091\n",
            "Epoch  55\n",
            "Error:  0.10776491467913901 \tAccuracy:  0.9138755980861244\n",
            "Epoch  56\n",
            "Error:  0.10631683953851494 \tAccuracy:  0.9138755980861244\n",
            "Epoch  57\n",
            "Error:  0.10489935823437496 \tAccuracy:  0.9138755980861244\n",
            "Epoch  58\n",
            "Error:  0.10349808675768525 \tAccuracy:  0.9138755980861244\n",
            "Epoch  59\n",
            "Error:  0.10211750063427329 \tAccuracy:  0.9138755980861244\n",
            "Epoch  60\n",
            "Error:  0.10077360351833402 \tAccuracy:  0.9138755980861244\n",
            "Epoch  61\n",
            "Error:  0.09946688002808403 \tAccuracy:  0.9186602870813397\n",
            "Epoch  62\n",
            "Error:  0.09820383258681717 \tAccuracy:  0.9186602870813397\n",
            "Epoch  63\n",
            "Error:  0.09699593286308775 \tAccuracy:  0.9186602870813397\n",
            "Epoch  64\n",
            "Error:  0.09583922918377494 \tAccuracy:  0.9186602870813397\n",
            "Epoch  65\n",
            "Error:  0.09472330469488477 \tAccuracy:  0.9186602870813397\n",
            "Epoch  66\n",
            "Error:  0.09364493344957014 \tAccuracy:  0.9234449760765551\n",
            "Epoch  67\n",
            "Error:  0.0925976370320781 \tAccuracy:  0.9234449760765551\n",
            "Epoch  68\n",
            "Error:  0.09156417111927705 \tAccuracy:  0.9234449760765551\n",
            "Epoch  69\n",
            "Error:  0.09053811238178869 \tAccuracy:  0.9234449760765551\n",
            "Epoch  70\n",
            "Error:  0.08952703936075969 \tAccuracy:  0.9234449760765551\n",
            "Epoch  71\n",
            "Error:  0.08856042600012799 \tAccuracy:  0.9234449760765551\n",
            "Epoch  72\n",
            "Error:  0.08764798586840652 \tAccuracy:  0.9234449760765551\n",
            "Epoch  73\n",
            "Error:  0.08677939015040642 \tAccuracy:  0.9234449760765551\n",
            "Epoch  74\n",
            "Error:  0.08594513829285565 \tAccuracy:  0.9234449760765551\n",
            "Epoch  75\n",
            "Error:  0.08513980915685992 \tAccuracy:  0.9234449760765551\n",
            "Epoch  76\n",
            "Error:  0.08436084117206129 \tAccuracy:  0.9234449760765551\n",
            "Epoch  77\n",
            "Error:  0.08360740094267534 \tAccuracy:  0.9282296650717703\n",
            "Epoch  78\n",
            "Error:  0.0828795800571415 \tAccuracy:  0.9282296650717703\n",
            "Epoch  79\n",
            "Error:  0.0821776833933654 \tAccuracy:  0.9282296650717703\n",
            "Epoch  80\n",
            "Error:  0.08150125796442498 \tAccuracy:  0.9234449760765551\n",
            "Epoch  81\n",
            "Error:  0.08084768898983274 \tAccuracy:  0.9234449760765551\n",
            "Epoch  82\n",
            "Error:  0.08021116351827731 \tAccuracy:  0.9234449760765551\n",
            "Epoch  83\n",
            "Error:  0.07958452930181233 \tAccuracy:  0.9234449760765551\n",
            "Epoch  84\n",
            "Error:  0.07896431321844506 \tAccuracy:  0.9234449760765551\n",
            "Epoch  85\n",
            "Error:  0.07835199104725539 \tAccuracy:  0.9234449760765551\n",
            "Epoch  86\n",
            "Error:  0.0777504504980726 \tAccuracy:  0.9234449760765551\n",
            "Epoch  87\n",
            "Error:  0.07716161754588638 \tAccuracy:  0.9234449760765551\n",
            "Epoch  88\n",
            "Error:  0.07658615763254831 \tAccuracy:  0.9234449760765551\n",
            "Epoch  89\n",
            "Error:  0.07602372594061942 \tAccuracy:  0.9282296650717703\n",
            "Epoch  90\n",
            "Error:  0.07547329402707449 \tAccuracy:  0.9282296650717703\n",
            "Epoch  91\n",
            "Error:  0.07493351711117044 \tAccuracy:  0.9282296650717703\n",
            "Epoch  92\n",
            "Error:  0.074403032439451 \tAccuracy:  0.9282296650717703\n",
            "Epoch  93\n",
            "Error:  0.07388057847006574 \tAccuracy:  0.9282296650717703\n",
            "Epoch  94\n",
            "Error:  0.07336494341751033 \tAccuracy:  0.9282296650717703\n",
            "Epoch  95\n",
            "Error:  0.07285485437619095 \tAccuracy:  0.9282296650717703\n",
            "Epoch  96\n",
            "Error:  0.0723489224608401 \tAccuracy:  0.9282296650717703\n",
            "Epoch  97\n",
            "Error:  0.0718456881754028 \tAccuracy:  0.9282296650717703\n",
            "Epoch  98\n",
            "Error:  0.07134374040506429 \tAccuracy:  0.9282296650717703\n",
            "Epoch  99\n",
            "Error:  0.07084187686566251 \tAccuracy:  0.9282296650717703\n",
            "Epoch  100\n",
            "Error:  0.07033933865303105 \tAccuracy:  0.9330143540669856\n",
            "Epoch  101\n",
            "Error:  0.0698361738712489 \tAccuracy:  0.9473684210526315\n",
            "Epoch  102\n",
            "Error:  0.06933359689192793 \tAccuracy:  0.9521531100478469\n",
            "Epoch  103\n",
            "Error:  0.06883393028864919 \tAccuracy:  0.9521531100478469\n",
            "Epoch  104\n",
            "Error:  0.06833990643031791 \tAccuracy:  0.9521531100478469\n",
            "Epoch  105\n",
            "Error:  0.06785377226593435 \tAccuracy:  0.9521531100478469\n",
            "Epoch  106\n",
            "Error:  0.06737680569109948 \tAccuracy:  0.9521531100478469\n",
            "Epoch  107\n",
            "Error:  0.06690931517088883 \tAccuracy:  0.9521531100478469\n",
            "Epoch  108\n",
            "Error:  0.06645052460884437 \tAccuracy:  0.9521531100478469\n",
            "Epoch  109\n",
            "Error:  0.06599634519877431 \tAccuracy:  0.9521531100478469\n",
            "Epoch  110\n",
            "Error:  0.06553124775355156 \tAccuracy:  0.9521531100478469\n",
            "Epoch  111\n",
            "Error:  0.06502487179343683 \tAccuracy:  0.9521531100478469\n",
            "Epoch  112\n",
            "Error:  0.06449152849817992 \tAccuracy:  0.9521531100478469\n",
            "Epoch  113\n",
            "Error:  0.06399238403506395 \tAccuracy:  0.9521531100478469\n",
            "Epoch  114\n",
            "Error:  0.06353783318066983 \tAccuracy:  0.9521531100478469\n",
            "Epoch  115\n",
            "Error:  0.06311322152622183 \tAccuracy:  0.9521531100478469\n",
            "Epoch  116\n",
            "Error:  0.06270878919507063 \tAccuracy:  0.9521531100478469\n",
            "Epoch  117\n",
            "Error:  0.062319997106229943 \tAccuracy:  0.9521531100478469\n",
            "Epoch  118\n",
            "Error:  0.06194459042562256 \tAccuracy:  0.9521531100478469\n",
            "Epoch  119\n",
            "Error:  0.06158118502460182 \tAccuracy:  0.9521531100478469\n",
            "Epoch  120\n",
            "Error:  0.06122870600268315 \tAccuracy:  0.9521531100478469\n",
            "Epoch  121\n",
            "Error:  0.06088617680473214 \tAccuracy:  0.9521531100478469\n",
            "Epoch  122\n",
            "Error:  0.06055266077776285 \tAccuracy:  0.9521531100478469\n",
            "Epoch  123\n",
            "Error:  0.060227306194045496 \tAccuracy:  0.9521531100478469\n",
            "Epoch  124\n",
            "Error:  0.059909512145130614 \tAccuracy:  0.9521531100478469\n",
            "Epoch  125\n",
            "Error:  0.059599211237003485 \tAccuracy:  0.9521531100478469\n",
            "Epoch  126\n",
            "Error:  0.05929707973741419 \tAccuracy:  0.9521531100478469\n",
            "Epoch  127\n",
            "Error:  0.05900426907032459 \tAccuracy:  0.9521531100478469\n",
            "Epoch  128\n",
            "Error:  0.05872161349306277 \tAccuracy:  0.9521531100478469\n",
            "Epoch  129\n",
            "Error:  0.05844906306673471 \tAccuracy:  0.9521531100478469\n",
            "Epoch  130\n",
            "Error:  0.05818584316250125 \tAccuracy:  0.9521531100478469\n",
            "Epoch  131\n",
            "Error:  0.05793091968990081 \tAccuracy:  0.9521531100478469\n",
            "Epoch  132\n",
            "Error:  0.05768330002158539 \tAccuracy:  0.9521531100478469\n",
            "Epoch  133\n",
            "Error:  0.057442120246508015 \tAccuracy:  0.9521531100478469\n",
            "Epoch  134\n",
            "Error:  0.057206627644167424 \tAccuracy:  0.9521531100478469\n",
            "Epoch  135\n",
            "Error:  0.05697613288699243 \tAccuracy:  0.9521531100478469\n",
            "Epoch  136\n",
            "Error:  0.056749958122334396 \tAccuracy:  0.9521531100478469\n",
            "Epoch  137\n",
            "Error:  0.0565273832574173 \tAccuracy:  0.9521531100478469\n",
            "Epoch  138\n",
            "Error:  0.056307582519354075 \tAccuracy:  0.9521531100478469\n",
            "Epoch  139\n",
            "Error:  0.056089535148931925 \tAccuracy:  0.9521531100478469\n",
            "Epoch  140\n",
            "Error:  0.055871882144536464 \tAccuracy:  0.9521531100478469\n",
            "Epoch  141\n",
            "Error:  0.05565269671861056 \tAccuracy:  0.9521531100478469\n",
            "Epoch  142\n",
            "Error:  0.05542922716879866 \tAccuracy:  0.9521531100478469\n",
            "Epoch  143\n",
            "Error:  0.0551980546334476 \tAccuracy:  0.9521531100478469\n",
            "Epoch  144\n",
            "Error:  0.05495638668749356 \tAccuracy:  0.9521531100478469\n",
            "Epoch  145\n",
            "Error:  0.05470382840250485 \tAccuracy:  0.9521531100478469\n",
            "Epoch  146\n",
            "Error:  0.054444106014265206 \tAccuracy:  0.9521531100478469\n",
            "Epoch  147\n",
            "Error:  0.05418768181621503 \tAccuracy:  0.9521531100478469\n",
            "Epoch  148\n",
            "Error:  0.053945477122512846 \tAccuracy:  0.9521531100478469\n",
            "Epoch  149\n",
            "Error:  0.053719173761600535 \tAccuracy:  0.9521531100478469\n",
            "Epoch  150\n",
            "Error:  0.053505059714219226 \tAccuracy:  0.9521531100478469\n",
            "Epoch  151\n",
            "Error:  0.05329958027004347 \tAccuracy:  0.9569377990430622\n",
            "Epoch  152\n",
            "Error:  0.05310037620170698 \tAccuracy:  0.9569377990430622\n",
            "Epoch  153\n",
            "Error:  0.05290586581902802 \tAccuracy:  0.9569377990430622\n",
            "Epoch  154\n",
            "Error:  0.0527148034304279 \tAccuracy:  0.9569377990430622\n",
            "Epoch  155\n",
            "Error:  0.05252597129451529 \tAccuracy:  0.9569377990430622\n",
            "Epoch  156\n",
            "Error:  0.05233800837817473 \tAccuracy:  0.9569377990430622\n",
            "Epoch  157\n",
            "Error:  0.052149526234726275 \tAccuracy:  0.9569377990430622\n",
            "Epoch  158\n",
            "Error:  0.05195965712002817 \tAccuracy:  0.9569377990430622\n",
            "Epoch  159\n",
            "Error:  0.05176862631046308 \tAccuracy:  0.9569377990430622\n",
            "Epoch  160\n",
            "Error:  0.051577558272210146 \tAccuracy:  0.9569377990430622\n",
            "Epoch  161\n",
            "Error:  0.051387720269808 \tAccuracy:  0.9569377990430622\n",
            "Epoch  162\n",
            "Error:  0.05120029948263641 \tAccuracy:  0.9569377990430622\n",
            "Epoch  163\n",
            "Error:  0.05101697885880694 \tAccuracy:  0.9569377990430622\n",
            "Epoch  164\n",
            "Error:  0.050840531776710204 \tAccuracy:  0.9569377990430622\n",
            "Epoch  165\n",
            "Error:  0.050670231511138766 \tAccuracy:  0.9569377990430622\n",
            "Epoch  166\n",
            "Error:  0.050467242295926355 \tAccuracy:  0.9569377990430622\n",
            "Epoch  167\n",
            "Error:  0.05018030248760487 \tAccuracy:  0.9569377990430622\n",
            "Epoch  168\n",
            "Error:  0.04992006572682634 \tAccuracy:  0.9569377990430622\n",
            "Epoch  169\n",
            "Error:  0.049712947612271186 \tAccuracy:  0.9569377990430622\n",
            "Epoch  170\n",
            "Error:  0.04952900836143385 \tAccuracy:  0.9569377990430622\n",
            "Epoch  171\n",
            "Error:  0.049357132284276316 \tAccuracy:  0.9569377990430622\n",
            "Epoch  172\n",
            "Error:  0.049196241247106094 \tAccuracy:  0.9569377990430622\n",
            "Epoch  173\n",
            "Error:  0.04905264905430344 \tAccuracy:  0.9569377990430622\n",
            "Epoch  174\n",
            "Error:  0.04893423898478263 \tAccuracy:  0.9569377990430622\n",
            "Epoch  175\n",
            "Error:  0.04876813731167308 \tAccuracy:  0.9569377990430622\n",
            "Epoch  176\n",
            "Error:  0.048362660543665725 \tAccuracy:  0.9569377990430622\n",
            "Epoch  177\n",
            "Error:  0.04795784873356847 \tAccuracy:  0.9569377990430622\n",
            "Epoch  178\n",
            "Error:  0.047716416662325484 \tAccuracy:  0.9569377990430622\n",
            "Epoch  179\n",
            "Error:  0.04751839951975996 \tAccuracy:  0.9569377990430622\n",
            "Epoch  180\n",
            "Error:  0.04730024334582735 \tAccuracy:  0.9569377990430622\n",
            "Epoch  181\n",
            "Error:  0.047411071345187704 \tAccuracy:  0.9569377990430622\n",
            "Epoch  182\n",
            "Error:  0.04722591691786023 \tAccuracy:  0.9569377990430622\n",
            "Epoch  183\n",
            "Error:  0.04641994078998539 \tAccuracy:  0.9569377990430622\n",
            "Epoch  184\n",
            "Error:  0.04532975264043624 \tAccuracy:  0.9569377990430622\n",
            "Epoch  185\n",
            "Error:  0.04459712709805628 \tAccuracy:  0.9569377990430622\n",
            "Epoch  186\n",
            "Error:  0.043991813482998444 \tAccuracy:  0.9569377990430622\n",
            "Epoch  187\n",
            "Error:  0.043552907571511354 \tAccuracy:  0.9617224880382775\n",
            "Epoch  188\n",
            "Error:  0.043293207622687076 \tAccuracy:  0.9617224880382775\n",
            "Epoch  189\n",
            "Error:  0.043151447204276085 \tAccuracy:  0.9617224880382775\n",
            "Epoch  190\n",
            "Error:  0.04282007208979765 \tAccuracy:  0.9617224880382775\n",
            "Epoch  191\n",
            "Error:  0.04223519015129305 \tAccuracy:  0.9617224880382775\n",
            "Epoch  192\n",
            "Error:  0.041905725541094827 \tAccuracy:  0.9617224880382775\n",
            "Epoch  193\n",
            "Error:  0.04189450352174333 \tAccuracy:  0.9617224880382775\n",
            "Epoch  194\n",
            "Error:  0.04140906795065849 \tAccuracy:  0.9617224880382775\n",
            "Epoch  195\n",
            "Error:  0.04067483916566599 \tAccuracy:  0.9617224880382775\n",
            "Epoch  196\n",
            "Error:  0.04041797940005662 \tAccuracy:  0.9617224880382775\n",
            "Epoch  197\n",
            "Error:  0.0401690644248097 \tAccuracy:  0.9617224880382775\n",
            "Epoch  198\n",
            "Error:  0.03991664079564125 \tAccuracy:  0.9617224880382775\n",
            "Epoch  199\n",
            "Error:  0.039653525993561575 \tAccuracy:  0.9617224880382775\n",
            "Epoch  200\n",
            "Error:  0.039396296410931717 \tAccuracy:  0.9617224880382775\n",
            "Epoch  201\n",
            "Error:  0.03917648066480597 \tAccuracy:  0.9617224880382775\n",
            "Epoch  202\n",
            "Error:  0.03900005404617046 \tAccuracy:  0.9617224880382775\n",
            "Epoch  203\n",
            "Error:  0.038792550929827245 \tAccuracy:  0.9665071770334929\n",
            "Epoch  204\n",
            "Error:  0.03840615412598903 \tAccuracy:  0.9665071770334929\n",
            "Epoch  205\n",
            "Error:  0.03796798146878218 \tAccuracy:  0.9665071770334929\n",
            "Epoch  206\n",
            "Error:  0.03753093366705288 \tAccuracy:  0.9665071770334929\n",
            "Epoch  207\n",
            "Error:  0.037081603848653936 \tAccuracy:  0.9665071770334929\n",
            "Epoch  208\n",
            "Error:  0.03659891399055019 \tAccuracy:  0.9665071770334929\n",
            "Epoch  209\n",
            "Error:  0.03609983975538682 \tAccuracy:  0.9665071770334929\n",
            "Epoch  210\n",
            "Error:  0.03565334807924218 \tAccuracy:  0.9665071770334929\n",
            "Epoch  211\n",
            "Error:  0.03525135286307233 \tAccuracy:  0.9665071770334929\n",
            "Epoch  212\n",
            "Error:  0.03476935091029948 \tAccuracy:  0.9665071770334929\n",
            "Epoch  213\n",
            "Error:  0.034315937567013295 \tAccuracy:  0.9665071770334929\n",
            "Epoch  214\n",
            "Error:  0.03389287726001022 \tAccuracy:  0.9712918660287081\n",
            "Epoch  215\n",
            "Error:  0.033298832424616266 \tAccuracy:  0.9712918660287081\n",
            "Epoch  216\n",
            "Error:  0.03287177314774658 \tAccuracy:  0.9712918660287081\n",
            "Epoch  217\n",
            "Error:  0.03247362930936679 \tAccuracy:  0.9712918660287081\n",
            "Epoch  218\n",
            "Error:  0.03206416279067441 \tAccuracy:  0.9712918660287081\n",
            "Epoch  219\n",
            "Error:  0.031642173503622244 \tAccuracy:  0.9712918660287081\n",
            "Epoch  220\n",
            "Error:  0.03124221348556312 \tAccuracy:  0.9712918660287081\n",
            "Epoch  221\n",
            "Error:  0.0308807371081899 \tAccuracy:  0.9712918660287081\n",
            "Epoch  222\n",
            "Error:  0.030566392373077473 \tAccuracy:  0.9712918660287081\n",
            "Epoch  223\n",
            "Error:  0.030283770759203438 \tAccuracy:  0.9712918660287081\n",
            "Epoch  224\n",
            "Error:  0.030007150799422136 \tAccuracy:  0.9712918660287081\n",
            "Epoch  225\n",
            "Error:  0.029717208066471674 \tAccuracy:  0.9808612440191388\n",
            "Epoch  226\n",
            "Error:  0.029401322337212196 \tAccuracy:  0.9808612440191388\n",
            "Epoch  227\n",
            "Error:  0.0290774362627978 \tAccuracy:  0.9808612440191388\n",
            "Epoch  228\n",
            "Error:  0.02878678816993232 \tAccuracy:  0.9808612440191388\n",
            "Epoch  229\n",
            "Error:  0.02853531431826785 \tAccuracy:  0.9808612440191388\n",
            "Epoch  230\n",
            "Error:  0.02831165953393581 \tAccuracy:  0.9808612440191388\n",
            "Epoch  231\n",
            "Error:  0.02805930874007875 \tAccuracy:  0.9808612440191388\n",
            "Epoch  232\n",
            "Error:  0.02761979837430604 \tAccuracy:  0.9808612440191388\n",
            "Epoch  233\n",
            "Error:  0.027381853057440942 \tAccuracy:  0.9808612440191388\n",
            "Epoch  234\n",
            "Error:  0.027190637206374383 \tAccuracy:  0.9808612440191388\n",
            "Epoch  235\n",
            "Error:  0.02701289840945618 \tAccuracy:  0.9808612440191388\n",
            "Epoch  236\n",
            "Error:  0.026842113757225648 \tAccuracy:  0.9808612440191388\n",
            "Epoch  237\n",
            "Error:  0.02667469037714304 \tAccuracy:  0.9808612440191388\n",
            "Epoch  238\n",
            "Error:  0.02650541662966001 \tAccuracy:  0.9808612440191388\n",
            "Epoch  239\n",
            "Error:  0.026320048483782953 \tAccuracy:  0.9808612440191388\n",
            "Epoch  240\n",
            "Error:  0.026101848955365704 \tAccuracy:  0.9808612440191388\n",
            "Epoch  241\n",
            "Error:  0.025877554342224107 \tAccuracy:  0.9808612440191388\n",
            "Epoch  242\n",
            "Error:  0.02566929227076052 \tAccuracy:  0.9808612440191388\n",
            "Epoch  243\n",
            "Error:  0.025470701774129304 \tAccuracy:  0.9808612440191388\n",
            "Epoch  244\n",
            "Error:  0.025265820190382864 \tAccuracy:  0.9808612440191388\n",
            "Epoch  245\n",
            "Error:  0.02489609480518227 \tAccuracy:  0.9808612440191388\n",
            "Epoch  246\n",
            "Error:  0.02453521428434028 \tAccuracy:  0.9808612440191388\n",
            "Epoch  247\n",
            "Error:  0.02430511232874647 \tAccuracy:  0.9808612440191388\n",
            "Epoch  248\n",
            "Error:  0.024096811495467895 \tAccuracy:  0.9808612440191388\n",
            "Epoch  249\n",
            "Error:  0.02388695523644977 \tAccuracy:  0.9808612440191388\n",
            "Epoch  250\n",
            "Error:  0.02366518351286197 \tAccuracy:  0.9808612440191388\n",
            "Epoch  251\n",
            "Error:  0.02344461085083565 \tAccuracy:  0.9808612440191388\n",
            "Epoch  252\n",
            "Error:  0.023238827240162137 \tAccuracy:  0.9808612440191388\n",
            "Epoch  253\n",
            "Error:  0.023042737806799017 \tAccuracy:  0.9808612440191388\n",
            "Epoch  254\n",
            "Error:  0.022827517893623202 \tAccuracy:  0.9808612440191388\n",
            "Epoch  255\n",
            "Error:  0.022448560121031684 \tAccuracy:  0.9856459330143541\n",
            "Epoch  256\n",
            "Error:  0.022187309037380296 \tAccuracy:  0.9856459330143541\n",
            "Epoch  257\n",
            "Error:  0.022015982547508132 \tAccuracy:  0.9856459330143541\n",
            "Epoch  258\n",
            "Error:  0.02186170150398309 \tAccuracy:  0.9856459330143541\n",
            "Epoch  259\n",
            "Error:  0.021713273785122608 \tAccuracy:  0.9856459330143541\n",
            "Epoch  260\n",
            "Error:  0.021565221253658597 \tAccuracy:  0.9856459330143541\n",
            "Epoch  261\n",
            "Error:  0.021411599833008707 \tAccuracy:  0.9856459330143541\n",
            "Epoch  262\n",
            "Error:  0.021245013962229525 \tAccuracy:  0.9856459330143541\n",
            "Epoch  263\n",
            "Error:  0.02106408711794916 \tAccuracy:  0.9904306220095693\n",
            "100% Accuracy reached. Stopping the training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQoSkWOrQP5q",
        "outputId": "537d1e68-6e74-4497-9ccf-7743408ddfa3"
      },
      "source": [
        "# With momentum test accuracy\n",
        "test_model(WB, x_test, y_test, layers)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted Output:  0.8822257683483712 \tTest Output:  1\n",
            "Predicted Output:  0.8752615558300514 \tTest Output:  1\n",
            "Predicted Output:  0.8826063861089379 \tTest Output:  1\n",
            "Predicted Output:  0.8756879141874951 \tTest Output:  1\n",
            "Predicted Output:  0.8495914158993794 \tTest Output:  1\n",
            "Predicted Output:  0.5731870298604704 \tTest Output:  0\n",
            "Predicted Output:  0.09355699347900902 \tTest Output:  1\n",
            "Predicted Output:  0.8805175265482263 \tTest Output:  1\n",
            "Predicted Output:  0.8795129153242215 \tTest Output:  1\n",
            "Predicted Output:  0.8317392726051875 \tTest Output:  1\n",
            "Predicted Output:  0.4982312352512401 \tTest Output:  1\n",
            "Predicted Output:  0.8356181832307548 \tTest Output:  1\n",
            "Predicted Output:  0.8254185658399451 \tTest Output:  1\n",
            "Predicted Output:  0.8823591030114804 \tTest Output:  0\n",
            "Predicted Output:  0.01721358088489199 \tTest Output:  0\n",
            "Predicted Output:  0.8620711931353103 \tTest Output:  1\n",
            "Predicted Output:  0.01555776671073621 \tTest Output:  0\n",
            "Predicted Output:  0.8680480315609085 \tTest Output:  1\n",
            "Predicted Output:  0.47310512855984177 \tTest Output:  1\n",
            "Predicted Output:  0.06781124341958822 \tTest Output:  1\n",
            "Predicted Output:  0.8819751873030737 \tTest Output:  1\n",
            "Predicted Output:  0.01771578346833572 \tTest Output:  0\n",
            "Predicted Output:  0.008771746562263243 \tTest Output:  0\n",
            "Predicted Output:  0.8788060874890455 \tTest Output:  1\n",
            "Predicted Output:  0.4859459798808394 \tTest Output:  1\n",
            "Predicted Output:  0.7770072874398347 \tTest Output:  1\n",
            "Predicted Output:  0.7439493227247072 \tTest Output:  1\n",
            "Predicted Output:  0.004345463334581954 \tTest Output:  0\n",
            "Predicted Output:  0.009504994132903854 \tTest Output:  1\n",
            "Predicted Output:  0.8833161555024757 \tTest Output:  0\n",
            "Predicted Output:  0.12454944762566554 \tTest Output:  1\n",
            "Predicted Output:  0.8763071607952393 \tTest Output:  1\n",
            "Predicted Output:  0.8633392741643785 \tTest Output:  1\n",
            "Predicted Output:  0.7550177705392156 \tTest Output:  1\n",
            "Predicted Output:  0.6046609827669849 \tTest Output:  0\n",
            "Predicted Output:  0.20487705696353536 \tTest Output:  0\n",
            "Predicted Output:  0.11885687002299386 \tTest Output:  0\n",
            "Predicted Output:  0.873321343551863 \tTest Output:  1\n",
            "Predicted Output:  0.5255568598305468 \tTest Output:  0\n",
            "Predicted Output:  0.037221192436778176 \tTest Output:  0\n",
            "Predicted Output:  0.8212596052928152 \tTest Output:  1\n",
            "Predicted Output:  0.5618440888811038 \tTest Output:  1\n",
            "Predicted Output:  0.8555272814990457 \tTest Output:  1\n",
            "Predicted Output:  0.008777637953878372 \tTest Output:  0\n",
            "Predicted Output:  0.8784164444676428 \tTest Output:  0\n",
            "Predicted Output:  0.7338539831112513 \tTest Output:  0\n",
            "Predicted Output:  0.6480163030846561 \tTest Output:  1\n",
            "Predicted Output:  0.8833392922191173 \tTest Output:  1\n",
            "Predicted Output:  0.7256545148412109 \tTest Output:  1\n",
            "Predicted Output:  0.20115392264215098 \tTest Output:  0\n",
            "Error:  0.18227797100969745 \tAccuracy:  0.72\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7F6KCU7DNXY"
      },
      "source": [
        "## References\n",
        "- [Step by Step Deep Neural Network](https://github.com/amanchadha/coursera-deep-learning-specialization/tree/master/C1%20-%20Neural%20Networks%20and%20Deep%20Learning/Week%204/Building%20your%20Deep%20Neural%20Network%20-%20Step%20by%20Step)"
      ]
    }
  ]
}